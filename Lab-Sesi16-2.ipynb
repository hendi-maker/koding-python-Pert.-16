{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/header.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Menggunakan tweepy untuk Data Crawler (Misal, sbg Upaya Tanggap Bencana) </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk\n",
    "#nltk.download(\"stopwords\")\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import Stream\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy.streaming import StreamListener\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re #regular expression\n",
    "from textblob import TextBlob\n",
    "import string\n",
    "import preprocessor as p\n",
    "import os\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Twitter credentials for the app\n",
    "consumer_key = \"JEj5tRSA9JWjWV6imMOrUIVWV\"        \n",
    "consumer_secret = \"7MEa00KHpUbjxble8pdlV74qPbvW2OHqLtjt45QQraJaAzRmAh\"\n",
    "access_key = \"935208713551364097-W9Oy0IS2M1dRUQS5MZ6Dnz18BkHUP80\"\n",
    "access_secret = \"jCANa7K7werTP2X1mnLlcRBFDHAJt9TZSCbC77FSNCj50\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pass twitter credentials to tweepy\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "#api = tweepy.API(auth)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True) # untuk solve error \"429 Too Many Requests response status code indicates the user has sent too many requests in a given amount of time (\"rate limiting\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ide Analsis Data Twitter (sbg contoh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/ide-analisis.png\" align=\"left\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create file paths for the 3 CSV files\n",
    "# declare file paths as follows for three files\n",
    "gempa_tweets = \"data/data_extraction/gempa_data.csv\"\n",
    "tsunami_tweets = \"data/data_extraction/tsunami_data.csv\"\n",
    "banjir_tweets = \"data/data_extraction/banjir_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Menentukan data nama-nama kolom untuk hasil ektraksi dari csv file\n",
    "#COLS = ['id','created_at','source','original_text','clean_text','sentiment','polarity','subjectivity','lang',\n",
    "#'favorite_count','retweet_count','original_author','possibly_sensitive','hashtags',\n",
    "#'user_mentions','place','place_coord_boundaries']\n",
    "\n",
    "COLS = ['id','created_at','source','original_text','clean_text','lang',\n",
    "'favorite_count','retweet_count','original_author','hashtags',\n",
    "'user_mentions','place','place_coord_boundaries']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/data-field.png\" align=\"left\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Declare HappyEmoticons\n",
    "emoticons_happy = set([\n",
    "    ':-)', ':)', ';)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)', ':}',\n",
    "    ':^)', ':-D', ':D', '8-D', '8D', 'x-D', 'xD', 'X-D', 'XD', '=-D', '=D',\n",
    "    '=-3', '=3', ':-))', \":'-)\", \":')\", ':*', ':^*', '>:P', ':-P', ':P', 'X-P',\n",
    "    'x-p', 'xp', 'XP', ':-p', ':p', '=p', ':-b', ':b', '>:)', '>;)', '>:-)',\n",
    "    '<3'\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declare Sad Emoticons\n",
    "emoticons_sad = set([\n",
    "    ':L', ':-/', '>:/', ':S', '>:[', ':@', ':-(', ':[', ':-||', '=L', ':<',\n",
    "    ':-[', ':-<', '=\\\\', '=/', '>:(', ':(', '>.<', \":'-(\", \":'(\", ':\\\\', ':-c',\n",
    "    ':c', ':{', '>:\\\\', ';('\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Emoji patterns\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "         u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "         u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "         u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "         u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "         u\"\\U00002702-\\U000027B0\"\n",
    "         u\"\\U000024C2-\\U0001F251\"\n",
    "         \"]+\", flags=re.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine sad and happy emoticons\n",
    "emoticons = emoticons_happy.union(emoticons_sad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# Cleaning the data\n",
    "def clean_tweets(tweet):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(tweet)\n",
    "\n",
    "    #after tweepy preprocessing the colon left remain after removing mentions\n",
    "    #or RT sign in the beginning of the tweet\n",
    "    tweet = re.sub(r':', '', tweet)\n",
    "    tweet = re.sub(r'‚Ä¶', '', tweet)\n",
    "    #replace consecutive non-ASCII characters with a space\n",
    "    tweet = re.sub(r'[^\\x00-\\x7F]+',' ', tweet)\n",
    "\n",
    "\n",
    "    #remove emojis from tweet\n",
    "    tweet = emoji_pattern.sub(r'', tweet)\n",
    "\n",
    "    #filter using NLTK library append it to a string\n",
    "    filtered_tweet = [w for w in word_tokens if not w in stop_words]\n",
    "    filtered_tweet = []\n",
    "\n",
    "    #looping through conditions\n",
    "    for w in word_tokens:\n",
    "        #check tokens against stop words , emoticons and punctuations\n",
    "        if w not in stop_words and w not in emoticons and w not in string.punctuation:\n",
    "            filtered_tweet.append(w)\n",
    "    return ' '.join(filtered_tweet)\n",
    "    #print(word_tokens)\n",
    "    #print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filecek=gempa_tweets\n",
    "#print(filecek)\n",
    "#os.path.exists(filecek)\n",
    "#csvFile = open(filecek, 'a' ,encoding='utf-8')\n",
    "#print(csvFile)\n",
    "\n",
    "#filecek=tsunami_tweets\n",
    "#print(filecek)\n",
    "#os.path.exists(filecek)\n",
    "#csvFile = open(filecek, 'a' ,encoding='utf-8')\n",
    "#print(csvFile)\n",
    "\n",
    "#filecek=banjir_tweets\n",
    "#print(filecek)\n",
    "#os.path.exists(filecek)\n",
    "#csvFile = open(filecek, 'a' ,encoding='utf-8')\n",
    "#print(csvFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method write_tweets()\n",
    "start_date='2019-01-31';\n",
    "def write_tweets(keyword, file):\n",
    "    # If the file exists, then read the existing data from the CSV file.\n",
    "    if os.path.exists(file):\n",
    "        #df = pd.read_csv(file, header=0)\n",
    "        try:\n",
    "            df = pd.read_csv(file, header=0)\n",
    "        except pd.io.common.EmptyDataError:\n",
    "            print(file, \" is empty and has been skipped.\")\n",
    "            df = pd.DataFrame(columns=COLS)\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=COLS)\n",
    "    \n",
    "    csvFile = open(file, 'a' ,encoding='utf-8')\n",
    "    \n",
    "    #page attribute in tweepy.cursor and iteration\n",
    "    #for page in tweepy.Cursor(api.search, q=keyword, \\\n",
    "                              #count=200, include_rts=False, since=start_date).pages(50):\n",
    "    #for page in tweepy.Cursor(api.search, q=keyword,count=10, include_rts=False, since=start_date).pages():\n",
    "    for status in tweepy.Cursor(api.search, q=keyword, include_rts=False, since=start_date, \\\n",
    "                                tweet_mode='extended').items(5):\n",
    "        #for status in page:\n",
    "        new_entry = []\n",
    "        status = status._json\n",
    "\n",
    "        ## check whether the tweet is in english or skip to the next tweet\n",
    "        #if status['lang'] != 'id':\n",
    "        #    print(status['lang'])\n",
    "        #    continue\n",
    "\n",
    "        #when run the code, below code replaces the retweet amount and\n",
    "        #no of favorires that are changed since last download.\n",
    "        print(status['created_at'])\n",
    "        print(df['created_at'])\n",
    "        if status['created_at'] in df['created_at'].values:  \n",
    "            i = df.loc[df['created_at'] == status['created_at']].index[0]\n",
    "            if status['favorite_count'] != df.at[i, 'favorite_count'] or \\\n",
    "               status['retweet_count'] != df.at[i, 'retweet_count']:\n",
    "                df.at[i, 'favorite_count'] = status['favorite_count']\n",
    "                df.at[i, 'retweet_count'] = status['retweet_count']\n",
    "            continue\n",
    "\n",
    "\n",
    "       #tweepy preprocessing called for basic preprocessing\n",
    "        #clean_text = p.clean(status['text'])\n",
    "\n",
    "        #call clean_tweet method for extra preprocessing\n",
    "        #filtered_tweet=clean_tweets(clean_text)\n",
    "        filtered_tweet=clean_tweets(status['full_text'])\n",
    "\n",
    "        #pass textBlob method for sentiment calculations\n",
    "        blob = TextBlob(filtered_tweet)\n",
    "        Sentiment = blob.sentiment\n",
    "\n",
    "        #seperate polarity and subjectivity in to two variables\n",
    "        polarity = Sentiment.polarity\n",
    "        subjectivity = Sentiment.subjectivity\n",
    "\n",
    "        #new entry append\n",
    "        #new_entry += [status['id'], status['created_at'],\n",
    "        #              status['source'], status['text'],filtered_tweet, Sentiment,polarity,subjectivity, status['lang'],\n",
    "        #              status['favorite_count'], status['retweet_count']]\n",
    "\n",
    "        new_entry += [status['id'], status['created_at'],\n",
    "                      status['source'], status['full_text'],filtered_tweet, status['lang'],\n",
    "                      status['favorite_count'], status['retweet_count']]\n",
    "\n",
    "        #to append original author of the tweet\n",
    "        new_entry.append(status['user']['screen_name'])\n",
    "\n",
    "        #try:\n",
    "        #    is_sensitive = status['possibly_sensitive']\n",
    "        #except KeyError:\n",
    "        #    is_sensitive = None\n",
    "        #new_entry.append(is_sensitive)\n",
    "\n",
    "        # hashtagas and mentiones are saved using comma separted\n",
    "        hashtags = \", \".join([hashtag_item['text'] for hashtag_item in status['entities']['hashtags']])\n",
    "        new_entry.append(hashtags)\n",
    "        mentions = \", \".join([mention['screen_name'] for mention in status['entities']['user_mentions']])\n",
    "        new_entry.append(mentions)\n",
    "\n",
    "        #get location of the tweet if possible\n",
    "        try:\n",
    "            location = status['user']['location']\n",
    "        except TypeError:\n",
    "            location = ''\n",
    "        new_entry.append(location)\n",
    "\n",
    "        try:\n",
    "            coordinates = [coord for loc in status['place']['bounding_box']['coordinates'] for coord in loc]\n",
    "        except TypeError:\n",
    "            coordinates = None\n",
    "        new_entry.append(coordinates)\n",
    "        print(new_entry)\n",
    "        single_tweet_df = pd.DataFrame([new_entry], columns=COLS)\n",
    "        df = df.append(single_tweet_df, ignore_index=True)\n",
    "        print(df)\n",
    "            #csvFile = open(file, 'a' ,encoding='utf-8')\n",
    "    return df.to_csv(csvFile, mode='a', columns=COLS, index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#declare keywords as a query untuk 3 kategori bencana\n",
    "gempa_keywords = '#gempa OR #gempabumi OR #gempalaut OR #Gempa OR #GEMPA'\n",
    "tsunami_keywords = '#tsunami OR #Tsunami OR #TSUNAMI OR #tsunamilaut OR #tsunamiawan'\n",
    "banjir_keywords = '#banjir OR #Banjir OR #BANJIR OR #banjirbandang'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jul 21 17:07:25 +0000 2019\n",
      "0     Sun Jul 21 16:53:24 +0000 2019\n",
      "1     Sun Jul 21 16:33:09 +0000 2019\n",
      "2     Sun Jul 21 16:27:55 +0000 2019\n",
      "3     Sun Jul 21 16:26:40 +0000 2019\n",
      "4     Sun Jul 21 16:21:02 +0000 2019\n",
      "5                         created_at\n",
      "6     Sun Jul 21 16:53:24 +0000 2019\n",
      "7     Sun Jul 21 16:33:09 +0000 2019\n",
      "8     Sun Jul 21 16:27:55 +0000 2019\n",
      "9     Sun Jul 21 16:26:40 +0000 2019\n",
      "10    Sun Jul 21 16:21:02 +0000 2019\n",
      "11    Sun Jul 21 17:07:25 +0000 2019\n",
      "12                        created_at\n",
      "13    Sun Jul 21 16:53:24 +0000 2019\n",
      "14    Sun Jul 21 16:33:09 +0000 2019\n",
      "15    Sun Jul 21 16:27:55 +0000 2019\n",
      "16    Sun Jul 21 16:26:40 +0000 2019\n",
      "17    Sun Jul 21 16:21:02 +0000 2019\n",
      "18                        created_at\n",
      "19    Sun Jul 21 16:53:24 +0000 2019\n",
      "20    Sun Jul 21 16:33:09 +0000 2019\n",
      "21    Sun Jul 21 16:27:55 +0000 2019\n",
      "22    Sun Jul 21 16:26:40 +0000 2019\n",
      "23    Sun Jul 21 16:21:02 +0000 2019\n",
      "24    Sun Jul 21 17:07:25 +0000 2019\n",
      "25    Sun Jul 21 16:09:01 +0000 2019\n",
      "Name: created_at, dtype: object\n",
      "Sun Jul 21 16:53:24 +0000 2019\n",
      "0     Sun Jul 21 16:53:24 +0000 2019\n",
      "1     Sun Jul 21 16:33:09 +0000 2019\n",
      "2     Sun Jul 21 16:27:55 +0000 2019\n",
      "3     Sun Jul 21 16:26:40 +0000 2019\n",
      "4     Sun Jul 21 16:21:02 +0000 2019\n",
      "5                         created_at\n",
      "6     Sun Jul 21 16:53:24 +0000 2019\n",
      "7     Sun Jul 21 16:33:09 +0000 2019\n",
      "8     Sun Jul 21 16:27:55 +0000 2019\n",
      "9     Sun Jul 21 16:26:40 +0000 2019\n",
      "10    Sun Jul 21 16:21:02 +0000 2019\n",
      "11    Sun Jul 21 17:07:25 +0000 2019\n",
      "12                        created_at\n",
      "13    Sun Jul 21 16:53:24 +0000 2019\n",
      "14    Sun Jul 21 16:33:09 +0000 2019\n",
      "15    Sun Jul 21 16:27:55 +0000 2019\n",
      "16    Sun Jul 21 16:26:40 +0000 2019\n",
      "17    Sun Jul 21 16:21:02 +0000 2019\n",
      "18                        created_at\n",
      "19    Sun Jul 21 16:53:24 +0000 2019\n",
      "20    Sun Jul 21 16:33:09 +0000 2019\n",
      "21    Sun Jul 21 16:27:55 +0000 2019\n",
      "22    Sun Jul 21 16:26:40 +0000 2019\n",
      "23    Sun Jul 21 16:21:02 +0000 2019\n",
      "24    Sun Jul 21 17:07:25 +0000 2019\n",
      "25    Sun Jul 21 16:09:01 +0000 2019\n",
      "Name: created_at, dtype: object\n",
      "Sun Jul 21 16:33:09 +0000 2019\n",
      "0     Sun Jul 21 16:53:24 +0000 2019\n",
      "1     Sun Jul 21 16:33:09 +0000 2019\n",
      "2     Sun Jul 21 16:27:55 +0000 2019\n",
      "3     Sun Jul 21 16:26:40 +0000 2019\n",
      "4     Sun Jul 21 16:21:02 +0000 2019\n",
      "5                         created_at\n",
      "6     Sun Jul 21 16:53:24 +0000 2019\n",
      "7     Sun Jul 21 16:33:09 +0000 2019\n",
      "8     Sun Jul 21 16:27:55 +0000 2019\n",
      "9     Sun Jul 21 16:26:40 +0000 2019\n",
      "10    Sun Jul 21 16:21:02 +0000 2019\n",
      "11    Sun Jul 21 17:07:25 +0000 2019\n",
      "12                        created_at\n",
      "13    Sun Jul 21 16:53:24 +0000 2019\n",
      "14    Sun Jul 21 16:33:09 +0000 2019\n",
      "15    Sun Jul 21 16:27:55 +0000 2019\n",
      "16    Sun Jul 21 16:26:40 +0000 2019\n",
      "17    Sun Jul 21 16:21:02 +0000 2019\n",
      "18                        created_at\n",
      "19    Sun Jul 21 16:53:24 +0000 2019\n",
      "20    Sun Jul 21 16:33:09 +0000 2019\n",
      "21    Sun Jul 21 16:27:55 +0000 2019\n",
      "22    Sun Jul 21 16:26:40 +0000 2019\n",
      "23    Sun Jul 21 16:21:02 +0000 2019\n",
      "24    Sun Jul 21 17:07:25 +0000 2019\n",
      "25    Sun Jul 21 16:09:01 +0000 2019\n",
      "Name: created_at, dtype: object\n",
      "Sun Jul 21 16:27:55 +0000 2019\n",
      "0     Sun Jul 21 16:53:24 +0000 2019\n",
      "1     Sun Jul 21 16:33:09 +0000 2019\n",
      "2     Sun Jul 21 16:27:55 +0000 2019\n",
      "3     Sun Jul 21 16:26:40 +0000 2019\n",
      "4     Sun Jul 21 16:21:02 +0000 2019\n",
      "5                         created_at\n",
      "6     Sun Jul 21 16:53:24 +0000 2019\n",
      "7     Sun Jul 21 16:33:09 +0000 2019\n",
      "8     Sun Jul 21 16:27:55 +0000 2019\n",
      "9     Sun Jul 21 16:26:40 +0000 2019\n",
      "10    Sun Jul 21 16:21:02 +0000 2019\n",
      "11    Sun Jul 21 17:07:25 +0000 2019\n",
      "12                        created_at\n",
      "13    Sun Jul 21 16:53:24 +0000 2019\n",
      "14    Sun Jul 21 16:33:09 +0000 2019\n",
      "15    Sun Jul 21 16:27:55 +0000 2019\n",
      "16    Sun Jul 21 16:26:40 +0000 2019\n",
      "17    Sun Jul 21 16:21:02 +0000 2019\n",
      "18                        created_at\n",
      "19    Sun Jul 21 16:53:24 +0000 2019\n",
      "20    Sun Jul 21 16:33:09 +0000 2019\n",
      "21    Sun Jul 21 16:27:55 +0000 2019\n",
      "22    Sun Jul 21 16:26:40 +0000 2019\n",
      "23    Sun Jul 21 16:21:02 +0000 2019\n",
      "24    Sun Jul 21 17:07:25 +0000 2019\n",
      "25    Sun Jul 21 16:09:01 +0000 2019\n",
      "Name: created_at, dtype: object\n",
      "Sun Jul 21 16:26:40 +0000 2019\n",
      "0     Sun Jul 21 16:53:24 +0000 2019\n",
      "1     Sun Jul 21 16:33:09 +0000 2019\n",
      "2     Sun Jul 21 16:27:55 +0000 2019\n",
      "3     Sun Jul 21 16:26:40 +0000 2019\n",
      "4     Sun Jul 21 16:21:02 +0000 2019\n",
      "5                         created_at\n",
      "6     Sun Jul 21 16:53:24 +0000 2019\n",
      "7     Sun Jul 21 16:33:09 +0000 2019\n",
      "8     Sun Jul 21 16:27:55 +0000 2019\n",
      "9     Sun Jul 21 16:26:40 +0000 2019\n",
      "10    Sun Jul 21 16:21:02 +0000 2019\n",
      "11    Sun Jul 21 17:07:25 +0000 2019\n",
      "12                        created_at\n",
      "13    Sun Jul 21 16:53:24 +0000 2019\n",
      "14    Sun Jul 21 16:33:09 +0000 2019\n",
      "15    Sun Jul 21 16:27:55 +0000 2019\n",
      "16    Sun Jul 21 16:26:40 +0000 2019\n",
      "17    Sun Jul 21 16:21:02 +0000 2019\n",
      "18                        created_at\n",
      "19    Sun Jul 21 16:53:24 +0000 2019\n",
      "20    Sun Jul 21 16:33:09 +0000 2019\n",
      "21    Sun Jul 21 16:27:55 +0000 2019\n",
      "22    Sun Jul 21 16:26:40 +0000 2019\n",
      "23    Sun Jul 21 16:21:02 +0000 2019\n",
      "24    Sun Jul 21 17:07:25 +0000 2019\n",
      "25    Sun Jul 21 16:09:01 +0000 2019\n",
      "Name: created_at, dtype: object\n",
      "Sun Jul 21 16:42:00 +0000 2019\n",
      "0     Sun Jul 21 16:42:00 +0000 2019\n",
      "1     Sun Jul 21 16:41:46 +0000 2019\n",
      "2     Sun Jul 21 16:39:26 +0000 2019\n",
      "3     Sun Jul 21 16:35:12 +0000 2019\n",
      "4     Sun Jul 21 16:26:40 +0000 2019\n",
      "5                         created_at\n",
      "6     Sun Jul 21 16:42:00 +0000 2019\n",
      "7     Sun Jul 21 16:41:46 +0000 2019\n",
      "8     Sun Jul 21 16:39:26 +0000 2019\n",
      "9     Sun Jul 21 16:35:12 +0000 2019\n",
      "10    Sun Jul 21 16:26:40 +0000 2019\n",
      "11                        created_at\n",
      "12    Sun Jul 21 16:42:00 +0000 2019\n",
      "13    Sun Jul 21 16:41:46 +0000 2019\n",
      "14    Sun Jul 21 16:39:26 +0000 2019\n",
      "15    Sun Jul 21 16:35:12 +0000 2019\n",
      "16    Sun Jul 21 16:26:40 +0000 2019\n",
      "17                        created_at\n",
      "18    Sun Jul 21 16:42:00 +0000 2019\n",
      "19    Sun Jul 21 16:41:46 +0000 2019\n",
      "20    Sun Jul 21 16:39:26 +0000 2019\n",
      "21    Sun Jul 21 16:35:12 +0000 2019\n",
      "22    Sun Jul 21 16:26:40 +0000 2019\n",
      "23    Sun Jul 21 15:54:39 +0000 2019\n",
      "24    Sun Jul 21 15:17:46 +0000 2019\n",
      "25    Sun Jul 21 15:17:41 +0000 2019\n",
      "26    Sun Jul 21 15:17:38 +0000 2019\n",
      "Name: created_at, dtype: object\n",
      "Sun Jul 21 16:41:46 +0000 2019\n",
      "0     Sun Jul 21 16:42:00 +0000 2019\n",
      "1     Sun Jul 21 16:41:46 +0000 2019\n",
      "2     Sun Jul 21 16:39:26 +0000 2019\n",
      "3     Sun Jul 21 16:35:12 +0000 2019\n",
      "4     Sun Jul 21 16:26:40 +0000 2019\n",
      "5                         created_at\n",
      "6     Sun Jul 21 16:42:00 +0000 2019\n",
      "7     Sun Jul 21 16:41:46 +0000 2019\n",
      "8     Sun Jul 21 16:39:26 +0000 2019\n",
      "9     Sun Jul 21 16:35:12 +0000 2019\n",
      "10    Sun Jul 21 16:26:40 +0000 2019\n",
      "11                        created_at\n",
      "12    Sun Jul 21 16:42:00 +0000 2019\n",
      "13    Sun Jul 21 16:41:46 +0000 2019\n",
      "14    Sun Jul 21 16:39:26 +0000 2019\n",
      "15    Sun Jul 21 16:35:12 +0000 2019\n",
      "16    Sun Jul 21 16:26:40 +0000 2019\n",
      "17                        created_at\n",
      "18    Sun Jul 21 16:42:00 +0000 2019\n",
      "19    Sun Jul 21 16:41:46 +0000 2019\n",
      "20    Sun Jul 21 16:39:26 +0000 2019\n",
      "21    Sun Jul 21 16:35:12 +0000 2019\n",
      "22    Sun Jul 21 16:26:40 +0000 2019\n",
      "23    Sun Jul 21 15:54:39 +0000 2019\n",
      "24    Sun Jul 21 15:17:46 +0000 2019\n",
      "25    Sun Jul 21 15:17:41 +0000 2019\n",
      "26    Sun Jul 21 15:17:38 +0000 2019\n",
      "Name: created_at, dtype: object\n",
      "Sun Jul 21 16:39:26 +0000 2019\n",
      "0     Sun Jul 21 16:42:00 +0000 2019\n",
      "1     Sun Jul 21 16:41:46 +0000 2019\n",
      "2     Sun Jul 21 16:39:26 +0000 2019\n",
      "3     Sun Jul 21 16:35:12 +0000 2019\n",
      "4     Sun Jul 21 16:26:40 +0000 2019\n",
      "5                         created_at\n",
      "6     Sun Jul 21 16:42:00 +0000 2019\n",
      "7     Sun Jul 21 16:41:46 +0000 2019\n",
      "8     Sun Jul 21 16:39:26 +0000 2019\n",
      "9     Sun Jul 21 16:35:12 +0000 2019\n",
      "10    Sun Jul 21 16:26:40 +0000 2019\n",
      "11                        created_at\n",
      "12    Sun Jul 21 16:42:00 +0000 2019\n",
      "13    Sun Jul 21 16:41:46 +0000 2019\n",
      "14    Sun Jul 21 16:39:26 +0000 2019\n",
      "15    Sun Jul 21 16:35:12 +0000 2019\n",
      "16    Sun Jul 21 16:26:40 +0000 2019\n",
      "17                        created_at\n",
      "18    Sun Jul 21 16:42:00 +0000 2019\n",
      "19    Sun Jul 21 16:41:46 +0000 2019\n",
      "20    Sun Jul 21 16:39:26 +0000 2019\n",
      "21    Sun Jul 21 16:35:12 +0000 2019\n",
      "22    Sun Jul 21 16:26:40 +0000 2019\n",
      "23    Sun Jul 21 15:54:39 +0000 2019\n",
      "24    Sun Jul 21 15:17:46 +0000 2019\n",
      "25    Sun Jul 21 15:17:41 +0000 2019\n",
      "26    Sun Jul 21 15:17:38 +0000 2019\n",
      "Name: created_at, dtype: object\n",
      "Sun Jul 21 16:35:12 +0000 2019\n",
      "0     Sun Jul 21 16:42:00 +0000 2019\n",
      "1     Sun Jul 21 16:41:46 +0000 2019\n",
      "2     Sun Jul 21 16:39:26 +0000 2019\n",
      "3     Sun Jul 21 16:35:12 +0000 2019\n",
      "4     Sun Jul 21 16:26:40 +0000 2019\n",
      "5                         created_at\n",
      "6     Sun Jul 21 16:42:00 +0000 2019\n",
      "7     Sun Jul 21 16:41:46 +0000 2019\n",
      "8     Sun Jul 21 16:39:26 +0000 2019\n",
      "9     Sun Jul 21 16:35:12 +0000 2019\n",
      "10    Sun Jul 21 16:26:40 +0000 2019\n",
      "11                        created_at\n",
      "12    Sun Jul 21 16:42:00 +0000 2019\n",
      "13    Sun Jul 21 16:41:46 +0000 2019\n",
      "14    Sun Jul 21 16:39:26 +0000 2019\n",
      "15    Sun Jul 21 16:35:12 +0000 2019\n",
      "16    Sun Jul 21 16:26:40 +0000 2019\n",
      "17                        created_at\n",
      "18    Sun Jul 21 16:42:00 +0000 2019\n",
      "19    Sun Jul 21 16:41:46 +0000 2019\n",
      "20    Sun Jul 21 16:39:26 +0000 2019\n",
      "21    Sun Jul 21 16:35:12 +0000 2019\n",
      "22    Sun Jul 21 16:26:40 +0000 2019\n",
      "23    Sun Jul 21 15:54:39 +0000 2019\n",
      "24    Sun Jul 21 15:17:46 +0000 2019\n",
      "25    Sun Jul 21 15:17:41 +0000 2019\n",
      "26    Sun Jul 21 15:17:38 +0000 2019\n",
      "Name: created_at, dtype: object\n",
      "Sun Jul 21 16:26:40 +0000 2019\n",
      "0     Sun Jul 21 16:42:00 +0000 2019\n",
      "1     Sun Jul 21 16:41:46 +0000 2019\n",
      "2     Sun Jul 21 16:39:26 +0000 2019\n",
      "3     Sun Jul 21 16:35:12 +0000 2019\n",
      "4     Sun Jul 21 16:26:40 +0000 2019\n",
      "5                         created_at\n",
      "6     Sun Jul 21 16:42:00 +0000 2019\n",
      "7     Sun Jul 21 16:41:46 +0000 2019\n",
      "8     Sun Jul 21 16:39:26 +0000 2019\n",
      "9     Sun Jul 21 16:35:12 +0000 2019\n",
      "10    Sun Jul 21 16:26:40 +0000 2019\n",
      "11                        created_at\n",
      "12    Sun Jul 21 16:42:00 +0000 2019\n",
      "13    Sun Jul 21 16:41:46 +0000 2019\n",
      "14    Sun Jul 21 16:39:26 +0000 2019\n",
      "15    Sun Jul 21 16:35:12 +0000 2019\n",
      "16    Sun Jul 21 16:26:40 +0000 2019\n",
      "17                        created_at\n",
      "18    Sun Jul 21 16:42:00 +0000 2019\n",
      "19    Sun Jul 21 16:41:46 +0000 2019\n",
      "20    Sun Jul 21 16:39:26 +0000 2019\n",
      "21    Sun Jul 21 16:35:12 +0000 2019\n",
      "22    Sun Jul 21 16:26:40 +0000 2019\n",
      "23    Sun Jul 21 15:54:39 +0000 2019\n",
      "24    Sun Jul 21 15:17:46 +0000 2019\n",
      "25    Sun Jul 21 15:17:41 +0000 2019\n",
      "26    Sun Jul 21 15:17:38 +0000 2019\n",
      "Name: created_at, dtype: object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jul 21 17:13:01 +0000 2019\n",
      "0     Sun Jul 21 17:00:34 +0000 2019\n",
      "1     Sun Jul 21 16:59:14 +0000 2019\n",
      "2     Sun Jul 21 16:57:32 +0000 2019\n",
      "3     Sun Jul 21 16:49:21 +0000 2019\n",
      "4     Sun Jul 21 16:47:22 +0000 2019\n",
      "5                         created_at\n",
      "6     Sun Jul 21 17:00:34 +0000 2019\n",
      "7     Sun Jul 21 16:59:14 +0000 2019\n",
      "8     Sun Jul 21 16:57:32 +0000 2019\n",
      "9     Sun Jul 21 16:49:21 +0000 2019\n",
      "10    Sun Jul 21 16:47:22 +0000 2019\n",
      "11    Sun Jul 21 17:05:16 +0000 2019\n",
      "12    Sun Jul 21 17:04:57 +0000 2019\n",
      "13    Sun Jul 21 17:04:27 +0000 2019\n",
      "14                        created_at\n",
      "15    Sun Jul 21 17:00:34 +0000 2019\n",
      "16    Sun Jul 21 16:59:14 +0000 2019\n",
      "17    Sun Jul 21 16:57:32 +0000 2019\n",
      "18    Sun Jul 21 16:49:21 +0000 2019\n",
      "19    Sun Jul 21 16:47:22 +0000 2019\n",
      "20                        created_at\n",
      "21    Sun Jul 21 17:00:34 +0000 2019\n",
      "22    Sun Jul 21 16:59:14 +0000 2019\n",
      "23    Sun Jul 21 16:57:32 +0000 2019\n",
      "24    Sun Jul 21 16:49:21 +0000 2019\n",
      "25    Sun Jul 21 16:47:22 +0000 2019\n",
      "26    Sun Jul 21 17:05:16 +0000 2019\n",
      "27    Sun Jul 21 17:04:57 +0000 2019\n",
      "28    Sun Jul 21 17:04:27 +0000 2019\n",
      "29    Sun Jul 21 17:11:02 +0000 2019\n",
      "Name: created_at, dtype: object\n",
      "[1152989870647681025, 'Sun Jul 21 17:13:01 +0000 2019', '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>', 'RT @BuletinTV3: Jurukamera TV3 Jatuh Bot!...\\n\\nInilah pengorbanan seorang pengamal media demi melaporkan apa-apa berita untuk negara.\\n\\n#Banj…', 'RT BuletinTV3 Jurukamera TV3 Jatuh Bot ... Inilah pengorbanan seorang pengamal media demi melaporkan apa-apa berita untuk negara Banj…', 'in', 0, 27832, 'HanieAzmi', '', 'BuletinTV3', '', None]\n",
      "                     id                      created_at  \\\n",
      "0   1152986736252747777  Sun Jul 21 17:00:34 +0000 2019   \n",
      "1   1152986401530449920  Sun Jul 21 16:59:14 +0000 2019   \n",
      "2   1152985976337096704  Sun Jul 21 16:57:32 +0000 2019   \n",
      "3   1152983917382684673  Sun Jul 21 16:49:21 +0000 2019   \n",
      "4   1152983417702645760  Sun Jul 21 16:47:22 +0000 2019   \n",
      "5                    id                      created_at   \n",
      "6   1152986736252747777  Sun Jul 21 17:00:34 +0000 2019   \n",
      "7   1152986401530449920  Sun Jul 21 16:59:14 +0000 2019   \n",
      "8   1152985976337096704  Sun Jul 21 16:57:32 +0000 2019   \n",
      "9   1152983917382684673  Sun Jul 21 16:49:21 +0000 2019   \n",
      "10  1152983417702645760  Sun Jul 21 16:47:22 +0000 2019   \n",
      "11  1152987921969848320  Sun Jul 21 17:05:16 +0000 2019   \n",
      "12  1152987842651381760  Sun Jul 21 17:04:57 +0000 2019   \n",
      "13  1152987714188222465  Sun Jul 21 17:04:27 +0000 2019   \n",
      "14                   id                      created_at   \n",
      "15  1152986736252747777  Sun Jul 21 17:00:34 +0000 2019   \n",
      "16  1152986401530449920  Sun Jul 21 16:59:14 +0000 2019   \n",
      "17  1152985976337096704  Sun Jul 21 16:57:32 +0000 2019   \n",
      "18  1152983917382684673  Sun Jul 21 16:49:21 +0000 2019   \n",
      "19  1152983417702645760  Sun Jul 21 16:47:22 +0000 2019   \n",
      "20                   id                      created_at   \n",
      "21  1152986736252747777  Sun Jul 21 17:00:34 +0000 2019   \n",
      "22  1152986401530449920  Sun Jul 21 16:59:14 +0000 2019   \n",
      "23  1152985976337096704  Sun Jul 21 16:57:32 +0000 2019   \n",
      "24  1152983917382684673  Sun Jul 21 16:49:21 +0000 2019   \n",
      "25  1152983417702645760  Sun Jul 21 16:47:22 +0000 2019   \n",
      "26  1152987921969848320  Sun Jul 21 17:05:16 +0000 2019   \n",
      "27  1152987842651381760  Sun Jul 21 17:04:57 +0000 2019   \n",
      "28  1152987714188222465  Sun Jul 21 17:04:27 +0000 2019   \n",
      "29  1152989372649656320  Sun Jul 21 17:11:02 +0000 2019   \n",
      "30  1152989870647681025  Sun Jul 21 17:13:01 +0000 2019   \n",
      "\n",
      "                                               source  \\\n",
      "0   <a href=\"http://twitter.com/download/iphone\" r...   \n",
      "1   <a href=\"http://twitter.com/download/iphone\" r...   \n",
      "2   <a href=\"http://twitter.com/download/android\" ...   \n",
      "3   <a href=\"https://petabencana.id\" rel=\"nofollow...   \n",
      "4   <a href=\"https://petabencana.id\" rel=\"nofollow...   \n",
      "5                                              source   \n",
      "6   <a href=\"http://twitter.com/download/iphone\" r...   \n",
      "7   <a href=\"http://twitter.com/download/iphone\" r...   \n",
      "8   <a href=\"http://twitter.com/download/android\" ...   \n",
      "9   <a href=\"https://petabencana.id\" rel=\"nofollow...   \n",
      "10  <a href=\"https://petabencana.id\" rel=\"nofollow...   \n",
      "11  <a href=\"http://twitter.com/download/android\" ...   \n",
      "12  <a href=\"http://twitter.com/download/android\" ...   \n",
      "13  <a href=\"http://twitter.com/download/android\" ...   \n",
      "14                                             source   \n",
      "15  <a href=\"http://twitter.com/download/iphone\" r...   \n",
      "16  <a href=\"http://twitter.com/download/iphone\" r...   \n",
      "17  <a href=\"http://twitter.com/download/android\" ...   \n",
      "18  <a href=\"https://petabencana.id\" rel=\"nofollow...   \n",
      "19  <a href=\"https://petabencana.id\" rel=\"nofollow...   \n",
      "20                                             source   \n",
      "21  <a href=\"http://twitter.com/download/iphone\" r...   \n",
      "22  <a href=\"http://twitter.com/download/iphone\" r...   \n",
      "23  <a href=\"http://twitter.com/download/android\" ...   \n",
      "24  <a href=\"https://petabencana.id\" rel=\"nofollow...   \n",
      "25  <a href=\"https://petabencana.id\" rel=\"nofollow...   \n",
      "26  <a href=\"http://twitter.com/download/android\" ...   \n",
      "27  <a href=\"http://twitter.com/download/android\" ...   \n",
      "28  <a href=\"http://twitter.com/download/android\" ...   \n",
      "29  <a href=\"http://twitter.com/download/iphone\" r...   \n",
      "30  <a href=\"http://twitter.com/download/iphone\" r...   \n",
      "\n",
      "                                        original_text  \\\n",
      "0   RT @BuletinTV3: Jurukamera TV3 Jatuh Bot!...\\r...   \n",
      "1   RT @BuletinTV3: Jurukamera TV3 Jatuh Bot!...\\r...   \n",
      "2   RT @BuletinTV3: Jurukamera TV3 Jatuh Bot!...\\r...   \n",
      "3   @rad17yo Halo, saya Bencana Bot. Untuk melapor...   \n",
      "4   @TiraaLuana Halo, saya Bencana Bot. Untuk mela...   \n",
      "5                                       original_text   \n",
      "6   RT @BuletinTV3: Jurukamera TV3 Jatuh Bot!...\\r...   \n",
      "7   RT @BuletinTV3: Jurukamera TV3 Jatuh Bot!...\\r...   \n",
      "8   RT @BuletinTV3: Jurukamera TV3 Jatuh Bot!...\\r...   \n",
      "9   @rad17yo Halo, saya Bencana Bot. Untuk melapor...   \n",
      "10  @TiraaLuana Halo, saya Bencana Bot. Untuk mela...   \n",
      "11  RT @BuletinTV3: Jurukamera TV3 Jatuh Bot!...\\r...   \n",
      "12  RT @BuletinTV3: Jurukamera TV3 Jatuh Bot!...\\r...   \n",
      "13  RT @BuletinTV3: Jurukamera TV3 Jatuh Bot!...\\r...   \n",
      "14                                      original_text   \n",
      "15  RT @BuletinTV3: Jurukamera TV3 Jatuh Bot!...\\r...   \n",
      "16  RT @BuletinTV3: Jurukamera TV3 Jatuh Bot!...\\r...   \n",
      "17  RT @BuletinTV3: Jurukamera TV3 Jatuh Bot!...\\r...   \n",
      "18  @rad17yo Halo, saya Bencana Bot. Untuk melapor...   \n",
      "19  @TiraaLuana Halo, saya Bencana Bot. Untuk mela...   \n",
      "20                                      original_text   \n",
      "21  RT @BuletinTV3: Jurukamera TV3 Jatuh Bot!...\\r...   \n",
      "22  RT @BuletinTV3: Jurukamera TV3 Jatuh Bot!...\\r...   \n",
      "23  RT @BuletinTV3: Jurukamera TV3 Jatuh Bot!...\\r...   \n",
      "24  @rad17yo Halo, saya Bencana Bot. Untuk melapor...   \n",
      "25  @TiraaLuana Halo, saya Bencana Bot. Untuk mela...   \n",
      "26  RT @BuletinTV3: Jurukamera TV3 Jatuh Bot!...\\r...   \n",
      "27  RT @BuletinTV3: Jurukamera TV3 Jatuh Bot!...\\r...   \n",
      "28  RT @BuletinTV3: Jurukamera TV3 Jatuh Bot!...\\r...   \n",
      "29  RT @BuletinTV3: Jurukamera TV3 Jatuh Bot!...\\r...   \n",
      "30  RT @BuletinTV3: Jurukamera TV3 Jatuh Bot!...\\n...   \n",
      "\n",
      "                                           clean_text  lang  favorite_count  \\\n",
      "0   RT BuletinTV3 Jurukamera TV3 Jatuh Bot ... Ini...    in               0   \n",
      "1   RT BuletinTV3 Jurukamera TV3 Jatuh Bot ... Ini...    in               0   \n",
      "2   RT BuletinTV3 Jurukamera TV3 Jatuh Bot ... Ini...    in               0   \n",
      "3   rad17yo Halo saya Bencana Bot Untuk melaporkan...    in               0   \n",
      "4   TiraaLuana Halo saya Bencana Bot Untuk melapor...    in               0   \n",
      "5                                          clean_text  lang  favorite_count   \n",
      "6   RT BuletinTV3 Jurukamera TV3 Jatuh Bot ... Ini...    in               0   \n",
      "7   RT BuletinTV3 Jurukamera TV3 Jatuh Bot ... Ini...    in               0   \n",
      "8   RT BuletinTV3 Jurukamera TV3 Jatuh Bot ... Ini...    in               0   \n",
      "9   rad17yo Halo saya Bencana Bot Untuk melaporkan...    in               0   \n",
      "10  TiraaLuana Halo saya Bencana Bot Untuk melapor...    in               0   \n",
      "11  RT BuletinTV3 Jurukamera TV3 Jatuh Bot ... Ini...    in               0   \n",
      "12  RT BuletinTV3 Jurukamera TV3 Jatuh Bot ... Ini...    in               0   \n",
      "13  RT BuletinTV3 Jurukamera TV3 Jatuh Bot ... Ini...    in               0   \n",
      "14                                         clean_text  lang  favorite_count   \n",
      "15  RT BuletinTV3 Jurukamera TV3 Jatuh Bot ... Ini...    in               0   \n",
      "16  RT BuletinTV3 Jurukamera TV3 Jatuh Bot ... Ini...    in               0   \n",
      "17  RT BuletinTV3 Jurukamera TV3 Jatuh Bot ... Ini...    in               0   \n",
      "18  rad17yo Halo saya Bencana Bot Untuk melaporkan...    in               0   \n",
      "19  TiraaLuana Halo saya Bencana Bot Untuk melapor...    in               0   \n",
      "20                                         clean_text  lang  favorite_count   \n",
      "21  RT BuletinTV3 Jurukamera TV3 Jatuh Bot ... Ini...    in               0   \n",
      "22  RT BuletinTV3 Jurukamera TV3 Jatuh Bot ... Ini...    in               0   \n",
      "23  RT BuletinTV3 Jurukamera TV3 Jatuh Bot ... Ini...    in               0   \n",
      "24  rad17yo Halo saya Bencana Bot Untuk melaporkan...    in               0   \n",
      "25  TiraaLuana Halo saya Bencana Bot Untuk melapor...    in               0   \n",
      "26  RT BuletinTV3 Jurukamera TV3 Jatuh Bot ... Ini...    in               0   \n",
      "27  RT BuletinTV3 Jurukamera TV3 Jatuh Bot ... Ini...    in               0   \n",
      "28  RT BuletinTV3 Jurukamera TV3 Jatuh Bot ... Ini...    in               0   \n",
      "29  RT BuletinTV3 Jurukamera TV3 Jatuh Bot ... Ini...    in               0   \n",
      "30  RT BuletinTV3 Jurukamera TV3 Jatuh Bot ... Ini...    in               0   \n",
      "\n",
      "    retweet_count  original_author  hashtags  user_mentions  \\\n",
      "0           27818  jeraayrhighness       NaN     BuletinTV3   \n",
      "1           27818      syakirkahar       NaN     BuletinTV3   \n",
      "2           27818          _bvpkhg       NaN     BuletinTV3   \n",
      "3               0      petabencana    banjir        rad17yo   \n",
      "4               0      petabencana    banjir     TiraaLuana   \n",
      "5   retweet_count  original_author  hashtags  user_mentions   \n",
      "6           27826  jeraayrhighness       NaN     BuletinTV3   \n",
      "7           27826      syakirkahar       NaN     BuletinTV3   \n",
      "8           27818          _bvpkhg       NaN     BuletinTV3   \n",
      "9               0      petabencana    banjir        rad17yo   \n",
      "10              0      petabencana    banjir     TiraaLuana   \n",
      "11          27826         apizaziq       NaN     BuletinTV3   \n",
      "12          27826         _diraeee       NaN     BuletinTV3   \n",
      "13          27826        piqamin10       NaN     BuletinTV3   \n",
      "14  retweet_count  original_author  hashtags  user_mentions   \n",
      "15          27828  jeraayrhighness       NaN     BuletinTV3   \n",
      "16          27818      syakirkahar       NaN     BuletinTV3   \n",
      "17          27818          _bvpkhg       NaN     BuletinTV3   \n",
      "18              0      petabencana    banjir        rad17yo   \n",
      "19              0      petabencana    banjir     TiraaLuana   \n",
      "20  retweet_count  original_author  hashtags  user_mentions   \n",
      "21          27826  jeraayrhighness       NaN     BuletinTV3   \n",
      "22          27826      syakirkahar       NaN     BuletinTV3   \n",
      "23          27818          _bvpkhg       NaN     BuletinTV3   \n",
      "24              0      petabencana    banjir        rad17yo   \n",
      "25              0      petabencana    banjir     TiraaLuana   \n",
      "26          27828         apizaziq       NaN     BuletinTV3   \n",
      "27          27828         _diraeee       NaN     BuletinTV3   \n",
      "28          27828        piqamin10       NaN     BuletinTV3   \n",
      "29          27828    AlyaaArshavin       NaN     BuletinTV3   \n",
      "30          27832        HanieAzmi               BuletinTV3   \n",
      "\n",
      "                 place  place_coord_boundaries  \n",
      "0   Selangor, Malaysia                     NaN  \n",
      "1              mia4eva                     NaN  \n",
      "2             Malaysia                     NaN  \n",
      "3            Indonesia                     NaN  \n",
      "4            Indonesia                     NaN  \n",
      "5                place  place_coord_boundaries  \n",
      "6   Selangor, Malaysia                     NaN  \n",
      "7              mia4eva                     NaN  \n",
      "8             Malaysia                     NaN  \n",
      "9            Indonesia                     NaN  \n",
      "10           Indonesia                     NaN  \n",
      "11  Petaling, Selangor                     NaN  \n",
      "12                 NaN                     NaN  \n",
      "13                 NaN                     NaN  \n",
      "14               place  place_coord_boundaries  \n",
      "15  Selangor, Malaysia                     NaN  \n",
      "16             mia4eva                     NaN  \n",
      "17            Malaysia                     NaN  \n",
      "18           Indonesia                     NaN  \n",
      "19           Indonesia                     NaN  \n",
      "20               place  place_coord_boundaries  \n",
      "21  Selangor, Malaysia                     NaN  \n",
      "22             mia4eva                     NaN  \n",
      "23            Malaysia                     NaN  \n",
      "24           Indonesia                     NaN  \n",
      "25           Indonesia                     NaN  \n",
      "26  Petaling, Selangor                     NaN  \n",
      "27                 NaN                     NaN  \n",
      "28                 NaN                     NaN  \n",
      "29                 NaN                     NaN  \n",
      "30                                        None  \n",
      "Sun Jul 21 17:11:02 +0000 2019\n",
      "0     Sun Jul 21 17:00:34 +0000 2019\n",
      "1     Sun Jul 21 16:59:14 +0000 2019\n",
      "2     Sun Jul 21 16:57:32 +0000 2019\n",
      "3     Sun Jul 21 16:49:21 +0000 2019\n",
      "4     Sun Jul 21 16:47:22 +0000 2019\n",
      "5                         created_at\n",
      "6     Sun Jul 21 17:00:34 +0000 2019\n",
      "7     Sun Jul 21 16:59:14 +0000 2019\n",
      "8     Sun Jul 21 16:57:32 +0000 2019\n",
      "9     Sun Jul 21 16:49:21 +0000 2019\n",
      "10    Sun Jul 21 16:47:22 +0000 2019\n",
      "11    Sun Jul 21 17:05:16 +0000 2019\n",
      "12    Sun Jul 21 17:04:57 +0000 2019\n",
      "13    Sun Jul 21 17:04:27 +0000 2019\n",
      "14                        created_at\n",
      "15    Sun Jul 21 17:00:34 +0000 2019\n",
      "16    Sun Jul 21 16:59:14 +0000 2019\n",
      "17    Sun Jul 21 16:57:32 +0000 2019\n",
      "18    Sun Jul 21 16:49:21 +0000 2019\n",
      "19    Sun Jul 21 16:47:22 +0000 2019\n",
      "20                        created_at\n",
      "21    Sun Jul 21 17:00:34 +0000 2019\n",
      "22    Sun Jul 21 16:59:14 +0000 2019\n",
      "23    Sun Jul 21 16:57:32 +0000 2019\n",
      "24    Sun Jul 21 16:49:21 +0000 2019\n",
      "25    Sun Jul 21 16:47:22 +0000 2019\n",
      "26    Sun Jul 21 17:05:16 +0000 2019\n",
      "27    Sun Jul 21 17:04:57 +0000 2019\n",
      "28    Sun Jul 21 17:04:27 +0000 2019\n",
      "29    Sun Jul 21 17:11:02 +0000 2019\n",
      "30    Sun Jul 21 17:13:01 +0000 2019\n",
      "Name: created_at, dtype: object\n",
      "Sun Jul 21 17:05:16 +0000 2019\n",
      "0     Sun Jul 21 17:00:34 +0000 2019\n",
      "1     Sun Jul 21 16:59:14 +0000 2019\n",
      "2     Sun Jul 21 16:57:32 +0000 2019\n",
      "3     Sun Jul 21 16:49:21 +0000 2019\n",
      "4     Sun Jul 21 16:47:22 +0000 2019\n",
      "5                         created_at\n",
      "6     Sun Jul 21 17:00:34 +0000 2019\n",
      "7     Sun Jul 21 16:59:14 +0000 2019\n",
      "8     Sun Jul 21 16:57:32 +0000 2019\n",
      "9     Sun Jul 21 16:49:21 +0000 2019\n",
      "10    Sun Jul 21 16:47:22 +0000 2019\n",
      "11    Sun Jul 21 17:05:16 +0000 2019\n",
      "12    Sun Jul 21 17:04:57 +0000 2019\n",
      "13    Sun Jul 21 17:04:27 +0000 2019\n",
      "14                        created_at\n",
      "15    Sun Jul 21 17:00:34 +0000 2019\n",
      "16    Sun Jul 21 16:59:14 +0000 2019\n",
      "17    Sun Jul 21 16:57:32 +0000 2019\n",
      "18    Sun Jul 21 16:49:21 +0000 2019\n",
      "19    Sun Jul 21 16:47:22 +0000 2019\n",
      "20                        created_at\n",
      "21    Sun Jul 21 17:00:34 +0000 2019\n",
      "22    Sun Jul 21 16:59:14 +0000 2019\n",
      "23    Sun Jul 21 16:57:32 +0000 2019\n",
      "24    Sun Jul 21 16:49:21 +0000 2019\n",
      "25    Sun Jul 21 16:47:22 +0000 2019\n",
      "26    Sun Jul 21 17:05:16 +0000 2019\n",
      "27    Sun Jul 21 17:04:57 +0000 2019\n",
      "28    Sun Jul 21 17:04:27 +0000 2019\n",
      "29    Sun Jul 21 17:11:02 +0000 2019\n",
      "30    Sun Jul 21 17:13:01 +0000 2019\n",
      "Name: created_at, dtype: object\n",
      "Sun Jul 21 17:04:57 +0000 2019\n",
      "0     Sun Jul 21 17:00:34 +0000 2019\n",
      "1     Sun Jul 21 16:59:14 +0000 2019\n",
      "2     Sun Jul 21 16:57:32 +0000 2019\n",
      "3     Sun Jul 21 16:49:21 +0000 2019\n",
      "4     Sun Jul 21 16:47:22 +0000 2019\n",
      "5                         created_at\n",
      "6     Sun Jul 21 17:00:34 +0000 2019\n",
      "7     Sun Jul 21 16:59:14 +0000 2019\n",
      "8     Sun Jul 21 16:57:32 +0000 2019\n",
      "9     Sun Jul 21 16:49:21 +0000 2019\n",
      "10    Sun Jul 21 16:47:22 +0000 2019\n",
      "11    Sun Jul 21 17:05:16 +0000 2019\n",
      "12    Sun Jul 21 17:04:57 +0000 2019\n",
      "13    Sun Jul 21 17:04:27 +0000 2019\n",
      "14                        created_at\n",
      "15    Sun Jul 21 17:00:34 +0000 2019\n",
      "16    Sun Jul 21 16:59:14 +0000 2019\n",
      "17    Sun Jul 21 16:57:32 +0000 2019\n",
      "18    Sun Jul 21 16:49:21 +0000 2019\n",
      "19    Sun Jul 21 16:47:22 +0000 2019\n",
      "20                        created_at\n",
      "21    Sun Jul 21 17:00:34 +0000 2019\n",
      "22    Sun Jul 21 16:59:14 +0000 2019\n",
      "23    Sun Jul 21 16:57:32 +0000 2019\n",
      "24    Sun Jul 21 16:49:21 +0000 2019\n",
      "25    Sun Jul 21 16:47:22 +0000 2019\n",
      "26    Sun Jul 21 17:05:16 +0000 2019\n",
      "27    Sun Jul 21 17:04:57 +0000 2019\n",
      "28    Sun Jul 21 17:04:27 +0000 2019\n",
      "29    Sun Jul 21 17:11:02 +0000 2019\n",
      "30    Sun Jul 21 17:13:01 +0000 2019\n",
      "Name: created_at, dtype: object\n",
      "Sun Jul 21 17:04:27 +0000 2019\n",
      "0     Sun Jul 21 17:00:34 +0000 2019\n",
      "1     Sun Jul 21 16:59:14 +0000 2019\n",
      "2     Sun Jul 21 16:57:32 +0000 2019\n",
      "3     Sun Jul 21 16:49:21 +0000 2019\n",
      "4     Sun Jul 21 16:47:22 +0000 2019\n",
      "5                         created_at\n",
      "6     Sun Jul 21 17:00:34 +0000 2019\n",
      "7     Sun Jul 21 16:59:14 +0000 2019\n",
      "8     Sun Jul 21 16:57:32 +0000 2019\n",
      "9     Sun Jul 21 16:49:21 +0000 2019\n",
      "10    Sun Jul 21 16:47:22 +0000 2019\n",
      "11    Sun Jul 21 17:05:16 +0000 2019\n",
      "12    Sun Jul 21 17:04:57 +0000 2019\n",
      "13    Sun Jul 21 17:04:27 +0000 2019\n",
      "14                        created_at\n",
      "15    Sun Jul 21 17:00:34 +0000 2019\n",
      "16    Sun Jul 21 16:59:14 +0000 2019\n",
      "17    Sun Jul 21 16:57:32 +0000 2019\n",
      "18    Sun Jul 21 16:49:21 +0000 2019\n",
      "19    Sun Jul 21 16:47:22 +0000 2019\n",
      "20                        created_at\n",
      "21    Sun Jul 21 17:00:34 +0000 2019\n",
      "22    Sun Jul 21 16:59:14 +0000 2019\n",
      "23    Sun Jul 21 16:57:32 +0000 2019\n",
      "24    Sun Jul 21 16:49:21 +0000 2019\n",
      "25    Sun Jul 21 16:47:22 +0000 2019\n",
      "26    Sun Jul 21 17:05:16 +0000 2019\n",
      "27    Sun Jul 21 17:04:57 +0000 2019\n",
      "28    Sun Jul 21 17:04:27 +0000 2019\n",
      "29    Sun Jul 21 17:11:02 +0000 2019\n",
      "30    Sun Jul 21 17:13:01 +0000 2019\n",
      "Name: created_at, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#call main method passing keywords and file path\n",
    "write_tweets(gempa_keywords,  gempa_tweets)\n",
    "write_tweets(tsunami_keywords, tsunami_tweets)\n",
    "write_tweets(banjir_keywords, banjir_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"img/thumbs-up.png\"></img>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
